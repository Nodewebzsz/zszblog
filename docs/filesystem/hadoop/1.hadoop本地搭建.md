##0. 环境准备
```shell
# 192.168.178.153
# 1C2G
```
##1. 下载jdk8的二进制包
```shell
# https://www.oracle.com/java/technologies/javase/javase8u211-later-archive-downloads.html
jdk-8u301-linux-x64.tar.gz
```
##2. 下载hadoop的二进制包
```shell
# https://hadoop.apache.org/
hadoop-2.10.1.tar.gz  
```
##3. 上传jkd8和hadoop
```shell
[root@153 ~]# ls
anaconda-ks.cfg  hadoop-2.10.1.tar.gz  jdk-8u301-linux-x64.tar.gz
```
##4. 创建centos用户
```shell
# 使用centos用户安装hadoop
useradd centos

## 添加密码：123456
passwd centos
```
##5. 赋予centos用户sudo权限
```shell
[root@153 ~]# vim /etc/sudoers
# 在100行后面，添加一行
 99 ## Allow root to run any commands anywhere
100 root    ALL=(ALL)       ALL
101 centos  ALL=(ALL)       ALL
```
##6. 更改二进制包权限
```shell
chown centos.centos hadoop-2.10.1.tar.gz  jdk-8u301-linux-x64.tar.gz
```
##7. 切换到centos用户
```shell
su - centos
```
##8. 创建/soft目录
```shell
sudo mkdir /soft
sudo chown centos.centos /soft
```
##9. 解压缩二进制包到/soft目录
```shell
sudo tar -zxvf /root/hadoop-2.10.1.tar.gz  -C /soft
sudo tar -zxvf /root/jdk-8u301-linux-x64.tar.gz -C /soft
ls /soft

[centos@153 ~]$ ls /soft
hadoop-2.10.1  jdk1.8.0_301

```
##10. 创建软连接
```shell
sudo chown -R centos.centos /soft
cd /soft
ln -s hadoop-2.10.1 hadoop 
ln -s jdk1.8.0_301 jdk
ls 
```
##11. 添加环境变量
```shell
sudo vim /etc/profile
# 在最后，添加以下几行

# jdk环境变量
export JAVA_HOME=/soft/jdk
export PATH=$PATH:$JAVA_HOME/bin

# hadoop环境变量
export HADOOP_HOME=/soft/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```
##12. 使环境变量生效
```shell
source /etc/profile
```
##13. 查看jdk和hadoop版本
```shell
java -version
hadoop version
```
```shell
[centos@153 soft]$ java -version
java version "1.8.0_301"
Java(TM) SE Runtime Environment (build 1.8.0_301-b09)
Java HotSpot(TM) 64-Bit Server VM (build 25.301-b09, mixed mode)
[centos@153 soft]$ hadoop version
Hadoop 2.10.1
Subversion https://github.com/apache/hadoop -r 1827467c9a56f133025f28557bfc2c562d78e816
Compiled by centos on 2020-09-14T13:17Z
Compiled with protoc 2.5.0
From source with checksum 3114edef868f1f3824e7d0f68be03650
This command was run using /soft/hadoop-2.10.1/share/hadoop/common/hadoop-common-2.10.1.jar
```
##14. 测试hadoop的增删改查
####1. 查看命令帮助
```shell
hdfs dfs
```
```shell
[centos@153 soft]$ hdfs dfs
Usage: hadoop fs [generic options]
        [-appendToFile <localsrc> ... <dst>]
        [-cat [-ignoreCrc] <src> ...]
        [-checksum <src> ...]
        [-chgrp [-R] GROUP PATH...]
        [-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
        [-chown [-R] [OWNER][:[GROUP]] PATH...]
        [-copyFromLocal [-f] [-p] [-l] [-d] <localsrc> ... <dst>]
        [-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] <path> ...]
        [-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]
        [-createSnapshot <snapshotDir> [<snapshotName>]]
        [-deleteSnapshot <snapshotDir> <snapshotName>]
        [-df [-h] [<path> ...]]
        [-du [-s] [-h] [-x] <path> ...]
        [-expunge]
        [-find <path> ... <expression> ...]
        [-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-getfacl [-R] <path>]
        [-getfattr [-R] {-n name | -d} [-e en] <path>]
        [-getmerge [-nl] [-skip-empty-file] <src> <localdst>]
        [-help [cmd ...]]
        [-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [<path> ...]]
        [-mkdir [-p] <path> ...]
        [-moveFromLocal <localsrc> ... <dst>]
        [-moveToLocal <src> <localdst>]
        [-mv <src> ... <dst>]
        [-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]
        [-renameSnapshot <snapshotDir> <oldName> <newName>]
        [-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]
        [-rmdir [--ignore-fail-on-non-empty] <dir> ...]
        [-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
        [-setfattr {-n name [-v value] | -x name} <path>]
        [-setrep [-R] [-w] <rep> <path> ...]
        [-stat [format] <path> ...]
        [-tail [-f] <file>]
        [-test -[defsz] <path>]
        [-text [-ignoreCrc] <src> ...]
        [-touchz <path> ...]
        [-truncate [-w] <length> <path> ...]
        [-usage [cmd ...]]

Generic options supported are:
-conf <configuration file>        specify an application configuration file
-D <property=value>               define a value for a given property
-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.
-jt <local|resourcemanager:port>  specify a ResourceManager
-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster
-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath
-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines

The general command line syntax is:
command [genericOptions] [commandOptions]
```
####2. 增文件夹
```shell
cd
hdfs dfs -mkdir aaa bbb
hdfs dfs -ls
```
```shell
[centos@153 soft]$ cd
[centos@153 ~]$ hdfs dfs -mkdir aaa bbb
[centos@153 ~]$ hdfs dfs -ls
Found 6 items
-rw-------   1 centos centos         23 2021-12-13 18:02 .bash_history
-rw-r--r--   1 centos centos         18 2018-10-31 01:07 .bash_logout
-rw-r--r--   1 centos centos        193 2018-10-31 01:07 .bash_profile
-rw-r--r--   1 centos centos        231 2018-10-31 01:07 .bashrc
drwxrwxr-x   - centos centos          6 2021-12-13 18:21 aaa
drwxrwxr-x   - centos centos          6 2021-12-13 18:21 bbb
```
####3. 增文件
```shell
hdfs dfs -touchz hadoop.txt
hdfs dfs -ls
```
```shell
[centos@153 ~]$ hdfs dfs -touchz hadoop.txt
[centos@153 ~]$ hdfs dfs -ls
Found 7 items
-rw-------   1 centos centos         23 2021-12-13 18:02 .bash_history
-rw-r--r--   1 centos centos         18 2018-10-31 01:07 .bash_logout
-rw-r--r--   1 centos centos        193 2018-10-31 01:07 .bash_profile
-rw-r--r--   1 centos centos        231 2018-10-31 01:07 .bashrc
drwxrwxr-x   - centos centos          6 2021-12-13 18:21 aaa
drwxrwxr-x   - centos centos          6 2021-12-13 18:21 bbb
-rw-r--r--   1 centos centos          0 2021-12-13 18:21 hadoop.txt
```
####4. 删文件
```shell
hdfs dfs -rm hadoop.txt
hdfs dfs -rm aaa
hdfs dfs -ls
```
```shell
[centos@153 ~]$ hdfs dfs -rm hadoop.txt
21/12/13 18:23:05 INFO Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
Deleted hadoop.txt
[centos@153 ~]$ hdfs dfs -rm aaa
rm: `aaa': Is a directory
[centos@153 ~]$ hdfs dfs -ls
Found 6 items
-rw-------   1 centos centos         23 2021-12-13 18:02 .bash_history
-rw-r--r--   1 centos centos         18 2018-10-31 01:07 .bash_logout
-rw-r--r--   1 centos centos        193 2018-10-31 01:07 .bash_profile
-rw-r--r--   1 centos centos        231 2018-10-31 01:07 .bashrc
drwxrwxr-x   - centos centos          6 2021-12-13 18:21 aaa
drwxrwxr-x   - centos centos          6 2021-12-13 18:21 bbb
```
####5. 删文件夹
```shell
hdfs dfs -rmdir aaa
hdfs dfs -ls
```
```shell
[centos@153 ~]$ hdfs dfs -rmdir aaa
[centos@153 ~]$ hdfs dfs -ls
Found 5 items
-rw-------   1 centos centos         23 2021-12-13 18:02 .bash_history
-rw-r--r--   1 centos centos         18 2018-10-31 01:07 .bash_logout
-rw-r--r--   1 centos centos        193 2018-10-31 01:07 .bash_profile
-rw-r--r--   1 centos centos        231 2018-10-31 01:07 .bashrc
drwxrwxr-x   - centos centos          6 2021-12-13 18:21 bbb
```
####6. 查
```shell
hdfs dfs -ls
```